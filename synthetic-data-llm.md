# syntheticAI

https://zhuanlan.zhihu.com/p/659842245
动机：1）纯粹依赖真实诗句缺乏对数据的控制，真实数据的控制权只掌握在少数科技巨头手中。2）数据安全、隐私。
- 与传统的匿名工具相比，合成数据生成是一种安全、快速且可扩展的解决方案。
- 它通过自动化手动和日常数据准备来节省时间和成本。
- 现实世界的数据高度偏向于特定的结果或类别。 合成数据消除了这种偏差行为，并提供了对可能性的多样化看法。
- 它提供对数据的完全控制，开发人员可以调整参数以适应不断变化的环境。
- 借助合成数据，研究人员可以对可能不存在的场景进行建模，从而促进创新。
- 在不影响敏感数据的情况下，营销人员可以创建类似于真实客户旅程和行为的客户角色。
- 重新平衡功能可能有助于减少不准确和缺失信息，以提供全面且高质量的数据集。
- 合成数据可以在遵循隐私政策的同时，通过数据的公平分配来确保数据的公平性。
- 合成数据几乎可以应用于所有行业——IT 和软件、零售、金融、国防、医疗保健、农业、食品生产、建筑、游戏等等。

what：合成数据生成（Synthetic Data Generation）是由机器学习模型执行的数学和统计过程，这些模型使用真实的物体、人和环境进行训练。然而，输出数据不携带任何敏感数据，但保留了真实数据的行为特征。算法从原始数据中提取行为特征，并创建相同的数据孪生，但与原始数据完全无关。
生成合成数据后，Sogeti 会保留与原始数据在统计上相似但不存在任何同一性的数据特征和相关性。
该平台生成原始数据的版本以及识别缺失值和敏感信息的多个测试数据场景。
MDClone 在提供克隆但匿名的患者数据方面迈出了变革性的一步。 该技术有助于根据患者的真实统计特征创建合成数据，而无需此类患者。
自称为“隐私工程即服务”，可生成统计上等效的数据集，而无需原始来源的任何敏感客户数据。
与此相反，合成数据是在数字环境中生成的。这些数据是以一种成功模仿实际数据的基本属性的方式制造的，但它们并不是来自任何真实世界的事件。
有了各种生成合成数据的技术，为机器学习模型所需的训练数据很容易获得，使得合成数据作为真实数据的替代品显得非常有前景。然而，不能断言合成数据是否可以成为所有真实世界问题的答案。但这并不影响合成数据所提供的重要优势。

<img src="https://pic1.zhimg.com/v2-11c52c3cdbbb331670e1db05fac23acc_r.jpg">  

使用合成数据时的挑战和局限性
尽管合成数据为数据科学计划的企业提供了许多优势，但它仍然存在一些局限性：
- 1. 数据的可靠性：众所周知，任何机器学习/深度学习模型的质量仅与其数据来源相当。在这方面，合成数据的质量与输入数据和用于生成数据的模型的质量密切相关。需要确保源数据中没有偏见，否则这些可能会很好地反映在合成数据中。此外，应在使用它进行任何预测之前验证并验证数据的质量。
- 2. 复制异常值：合成数据只能类似于现实世界的数据，它不能是精确的副本。因此，合成数据可能不涵盖真实数据中存在的某些异常值。数据中的异常值可能比正常数据更重要。
- 3. 需要专业知识、时间和努力：尽管与真实数据相比，合成数据可能更容易且更便宜，但它确实需要一定的专业知识、时间和努力。
- 4. 用户接受度：合成数据是一个新概念，那些尚未看到其优势的人可能不准备信任基于它的预测。这意味着首先需要创建关于合成数据价值的意识，以推动更多用户的接受。
- 5. 质量检查和输出控制：创建合成数据的目的是模仿现实世界的数据。手动检查数据变得至关重要。对于使用算法自动生成的复杂数据集，确保在机器学习/深度学习模型中实施它之前确保数据的正确性是至关重要的。


合成数据的字符集较短。这是由于MOSTLY AI平台内的隐私机制，其中非常罕见的token被删除，以防止它们的存在泄露个人记录的存在信息。
https://mostly.ai/blog/synthetic-data-for-text-annotation


# 用GPT-4合成数据来训练AI模型，实现SOTA！

https://mp.weixin.qq.com/s/Dzkg-GBYiekQknhF_Q6lgQ

RAG是未来LLMs应用的重要趋势之一。

论文标题:
Improving Text Embeddings with Large Language Models
论文链接:
https://arxiv.org/pdf/2401.00368.pdf
模型:
https://huggingface.co/intfloat/e5-mistral-7b-instruct
数据：
https://huggingface.co/datasets/andersonbcdefg/synthetic_retrieval_tasks

作者使用GPT-4集思广益产生一系列潜在的检索任务，然后为每个任务生成(查询,正例,困难反例)三元组。

这篇工作证明了通过LLMs技术，文本嵌入的质量可以得到显著提升。研究人员使用了专有的LLMs（如GPT-4），在多种语言环境下生成了多样化的合成数据，并结合Mistral模型强大的语言理解能力，在竞争激烈的MTEB基准测试中取得了SOTA。与现有的多阶段方法相比，既简单又高效，不再需要中间预训练的环节。
用网友的话说就是“Amazing Amazing Amazing!”，省去了人工采集数据的繁琐步骤，每个人都可以轻松地生成自己的数据集，并训练强大的嵌入模型。语义检索模型不给力导致生成模型性能受影响的局面，总算有希望翻篇儿了！


# AI  Augmented AI

https://arxiv.org/pdf/2407.17453

Images with Human Texts (short, brief, real)  -> AI -> Images with Re-captioned Texts (long, detailed, synthetic) -> AI -> Images with SFT-augmented Texts (task-aware, synthetic) -> AI.

