# Distilling System 2 into System 1
https://arxiv.org/pdf/2407.06023
最近，人们提出了许多方法来使用 LLM 在内部循环中执行更深入的推理，其中它生成中间输出，有时称为 LLM 程序（Schlag等人，2023）。这些包括子问题分解（Perez等人，2020）、自我改进（Madaan等人，2024；Weston和Sukhbaatar，2023；Deng等人，2023a）、自我验证和询问（Press等人，2022；Weng等人，2022；Dhuliu-wala等人，2023）以及诸如树思维的各种搜索技术等（Yao等人，2024；Besta等人，2024）。 
生成中间深度推理的方法：
1. 链式思考（CoT）是一种由GPT-3提出的系统2（System 2）推理技术，其目的是让模型能够执行更复杂的推理任务。CoT的核心思想是让模型通过一系列步骤来解决问题，每个步骤都会产生一些中间结果，这些结果会被传递给下一个步骤，直到得出最终的答案。CoT的优点是可以解决许多不同的问题类型，但它需要更多的计算资源和时间来完成。
2. System 2注意力是另一种系统2（System 2）推理技术，它可以用来控制模型的注意力，以便更好地理解和处理输入。具体来说，System 2注意力可以通过调整模型的注意力权重来过滤掉不必要的信息，从而提高模型的性能。System 2注意力的优点是可以应用于各种不同类型的任务，但它也需要更多的计算资源和时间来完成。
3. 重述和响应（RaR）是一种系统2（System 2）推理技术，它可以帮助模型更好地理解和回答问题。具体来说，RaR可以让模型首先生成一个简短的回答，然后再将其扩展成更详细的回答。这种方法可以使模型更加准确地回答问题，但它也需要更多的计算资源和时间来完成。
4. 分支解决合并（BSM）是一种系统2（System 2）推理技术，它可以帮助模型更好地处理多个任务。具体来说，BSM可以将一个大的任务分解成多个小的任务，并分别处理每个任务。最后，BSM会将所有的结果合并起来，得到最终的结果。这种方法可以使模型更加高效地处理多个任务，但它也需要更多的计算资源和时间来完成。

这四种方法的共同点是它们都是系统2（System 2）推理技术，都需要更多的计算资源和时间来完成。不同之处在于它们的应用场景和实现方式。CoT适用于各种类型的推理任务，但需要更多的计算资源和时间；System 2注意力可以应用于各种不同类型的任务，但同样需要更多的计算资源和时间；RaR可以帮助模型更好地理解和回答问题，但同样需要更多的计算资源和时间；BSM可以帮助模型更好地处理多个任务，但同样需要更多的计算资源和时间。


# Orca LLM
https://www.microsoft.com/en-us/research/project/orca/
Orca LLM：专注于通过对基于示例的推理任务的新数据集进行训练来提高推理能力。它弥补了通用 LLM 和专用推理引擎之间的差距，增强了其解决复杂逻辑问题的能力。算法将复杂的定量和推理问题分解为分步解决方案。
它利用GPT-4的解释追踪、思考过程和复杂指令进行渐进学习，取得了显著的zero-shot推理成绩。
模型通过其庞大的规模和渐进学习方法，尤其是从复杂的解释和指导中学习，以及对大规模多样化的模仿数据的利用，取得了与Vicuna-13B等模型相比的显著优势，特别是在复杂的zero-shot推理基准测试中。这使得Orca成为处理各种任务和挑战的有力工具。
